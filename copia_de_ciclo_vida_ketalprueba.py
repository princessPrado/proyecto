# -*- coding: utf-8 -*-
"""Copia de Ciclo_vida_KetalPrueba.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jxzxI2ws6bwOS1LlhPdr-TeS9Rh25TB2
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.cluster import AgglomerativeClustering
from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.preprocessing import StandardScaler

# Commented out IPython magic to ensure Python compatibility.
import plotly.express as px
import plotly.graph_objs as go
import missingno as msno

import warnings 
warnings.filterwarnings('ignore')

plt.style.use('fivethirtyeight')
# %matplotlib inline
import time

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
import nltk
from nltk.tag import pos_tag
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, WordNetLemmatizer
from nltk.corpus import wordnet as wn
import re
from functools import lru_cache
import string
from tqdm import tqdm
tqdm.pandas()

from sklearn.metrics.pairwise import cosine_similarity

!pip install mlxtend

!pip install mlxtend --upgrade --no-deps

from mlxtend.frequent_patterns import fpgrowth
from mlxtend.frequent_patterns import association_rules
from mlxtend.preprocessing import TransactionEncoder

"""### Cargar datos"""

dataset = pd.read_excel('/content/gdrive/MyDrive/datos/datosmes41.xlsx')

dataset.head()

dataset_a = pd.read_excel('/content/gdrive/MyDrive/datos/Libro2.xlsx')

"""###Limpieza de datos"""

dataset.isnull().sum()

dataset.info()

dataset.describe()

dataset.describe().transpose()

dataset.corr()['CantidadTransaccion'].sort_values()

msno.bar(dataset)
plt.show

"""### Visualizacion de los datos"""

#este paso sirve para visualizar el comportamiento de los datos

import seaborn as sns
from scipy import stats

msno.bar(dataset)
plt.show

plt.figure(figsize=(20, 8))
plotnumber = 1

for col in ['Clientes_edad','Ciclo_de_Vida_sk','Centro_sk','CantidadTransaccion','MontoAcumuladoventaBs','MargenTotalBs']:
  if plotnumber <= 5:
    ax = plt.subplot(1,5, plotnumber)
    sns.distplot(dataset[col])
  plotnumber += 1

plt.tight_layout()
plt.show()

dataset.columns

dataset['Genero'].value_counts()

dataset['Centro_sk'].value_counts()

males_age=dataset[dataset["Genero"]=='MASCULINO']['Clientes_edad']
females_age=dataset[dataset["Genero"]=='FEMENINO']['Clientes_edad']

age_bins = range(18,80,5)

#males
fig2, (ax1, ax2, ) = plt.subplots(1, 2,  figsize=(14,8), sharey=True)
sns.distplot(males_age, bins=age_bins, kde=False, color='#0066ff', ax=ax1, hist_kws=dict(edgecolor="k", linewidth=2))
ax1.set_xticks(age_bins)
#ax1.set_ylim(top=25)
ax1.set_title('Males')
ax1.set_ylabel('Count')
ax1.text(55,2000, "TOTAL count: {}".format(males_age.count()))
ax1.text(55,1800, "Mean age: {:.1f}".format(males_age.mean()))

#females
sns.distplot(females_age, bins=age_bins, kde=False, color='#cc66ff', ax=ax2, hist_kws=dict(edgecolor="k", linewidth=2))
ax2.set_xticks(age_bins)
ax2.set_title('Females')
ax2.set_ylabel('Count')
ax2.text(55,2000, "TOTAL count: {}".format(females_age.count()))
ax2.text(55,1800, "Mean age: {:.1f}".format(females_age.mean()))


plt.show()

no_age=dataset[dataset["Genero"]=='NO INDICA']['Clientes_edad']

def labeler(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%\n({:d})".format(pct, absolute)

sizes = [males_age.count(), females_age.count(), no_age.count()] # wedge sizes

fig0, ax1 = plt.subplots(figsize=(6,6))
wedges, texts, autotexts = ax1.pie(sizes,
                                   autopct=lambda pct: labeler(pct, sizes),
                                   radius=1,
                                   colors=['#0066ff','#cc66ff','#00FF00'],
                                   startangle=90,
                                   textprops=dict(color="w"),
                                   wedgeprops=dict(width=0.7, edgecolor='w'))

ax1.legend(wedges, ['masculino','femenino','no tiene'],
           loc='upper right',
           bbox_to_anchor=(0.7, 0, 0.6, 1))

plt.text(0,0, 'TOTAL\n{}'.format(dataset['Clientes_edad'].count()),
         weight='bold', size=12, color='#52527a',
         ha='center', va='center')

plt.setp(autotexts, size=12, weight='bold')
ax1.axis('equal')  # Equal aspect ratio
plt.show()

plt.figure(figsize=(20,8))
plotnumber = 1

for col in ['Clientes_edad','Ciclo_de_Vida_sk','Centro_sk','CantidadTransaccion','MontoAcumuladoventaBs','MargenTotalBs']:
  if plotnumber <= 5:
    ax = plt.subplot(1,5, plotnumber)
    sns.violinplot(x = col, y = 'Genero', data = dataset)
  plotnumber += 1

plt.tight_layout()
plt.show()

edad_18_25 = dataset.Clientes_edad[(dataset.Clientes_edad >=18) & (dataset.Clientes_edad <=25)]
edad_26_35 = dataset.Clientes_edad[(dataset.Clientes_edad >=26) & (dataset.Clientes_edad <=35)]
edad_36_45 = dataset.Clientes_edad[(dataset.Clientes_edad >=36) & (dataset.Clientes_edad <=45)]
edad_46_55 = dataset.Clientes_edad[(dataset.Clientes_edad >=46) & (dataset.Clientes_edad <=55)]
edad_55a = dataset.Clientes_edad[dataset.Clientes_edad >=55]

x_age = ['18-25', '26-35', '36-45', '46-55', '55+']
y_age = [len(edad_18_25.values), len(edad_26_35.values), len(edad_36_45.values), len(edad_46_55.values),
     len(edad_55a.values)]

px.bar(data_frame = dataset, x = x_age, y = y_age, color = x_age,
       title = 'Numero de clientes por edad')

dataset.columns

px.scatter(data_frame = dataset, x = 'CantidadTransaccion', y = 
           'MontoAcumuladoventaBs',title = 'relacion entre cantidad de transaciones y montos')

px.scatter(data_frame = dataset, x = 'Ciclo_de_Vida_sk', y = 
           'CantidadTransaccion',title = 'relacion entre ciclo de vida y transaciones')

px.scatter(data_frame = dataset, x = 'Clientes_edad', y = 
           'MontoAcumuladoventaBs',title = 'relacion entre edad  y montos')

px.scatter(data_frame = dataset, x = 'Clientes_edad', y = 
           'Ciclo_de_Vida_sk',title = 'relacion entre cantidad de transaciones y montos')

dataset['Clientes_edad'].value_counts()

plt.figure(figsize=(12,7))
sns.heatmap(dataset.corr(),annot=True,cmap='viridis')
plt.ylim(10,0)

dataset.corr()['CantidadTransaccion'][:-1].sort_values().plot(kind='bar')

dataset.columns

"""### Kmeans"""

#Se utilizo el metodo del codo este sirve para ver cuantos cluster debemos utlizar para el modelo Kmeans   
#para saber que numero de cluster que se tiene que utilizar se tiene que ver cual es el mas alejado del punto donde se crea la curva
#para este caso se tiene dos posibilidades como ser el num 4 y num 5 

X1 = dataset.loc[:,['Clientes_edad','CantidadTransaccion']].values

wcss = []

for k in range(1,11):
  kmeans = KMeans(n_clusters = k, init = 'k-means++')
  kmeans.fit(X1)
  wcss.append(kmeans.inertia_)

plt.figure(figsize = (12,7))

plt.plot(range(1, 11), wcss, linewidth = 2, marker = '8')
plt.title('Metodo del codo\n', fontsize = 20)
plt.xlabel('Numero de cluster')
plt.ylabel('Distancia Promedio del centroide al cluster')
plt.show()

#Para el modelo Kmeans se utilizo 5 cluster   

kmeans = KMeans(n_clusters = 5)
labels = kmeans.fit_predict(X1)
print(labels)

#Aqui se muestra la posicicon de los clusteres

print(kmeans.cluster_centers_)

#aqui muestra en un plano 2D usando 2 campos para ver como se forman los grupos
#en este caso se utilizo la edad del cliente y la cantidad de trasaccion de esa manera 
#los puntos de cluster que son de color rojo estos son los puntos asignados para que se agrupen de esa manera  

plt.figure(figsize = (14, 8))

plt.scatter(X1[:, 0], X1[:, 1], c = kmeans.labels_, s = 105)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], color = 'red', s = 250)
plt.title('Clusters de clientes', fontsize = 20)
plt.xlabel('edad')
plt.ylabel('Cantidad Transaccion')
plt.show()

X2 = dataset.loc[:,['Ciclo_de_Vida_sk','CantidadTransaccion']].values

wcss = []

for k in range(1,11):
  kmeans1 = KMeans(n_clusters = k, init = 'k-means++')
  kmeans1.fit(X2)
  wcss.append(kmeans1.inertia_)

plt.figure(figsize = (12,7))

plt.plot(range(1, 11), wcss, linewidth = 2, marker = '8')
plt.title('Metodo del codo\n', fontsize = 20)
plt.xlabel('Numero de cluster')
plt.ylabel('Distancia Promedio del centroide al cluster')
plt.show()

kmeans1 = KMeans(n_clusters = 5)
labels = kmeans1.fit_predict(X2)
print(labels)

print(kmeans1.cluster_centers_)

plt.figure(figsize = (14, 8))

plt.scatter(X2[:, 0], X2[:, 1], c = kmeans1.labels_, s = 105)
plt.scatter(kmeans1.cluster_centers_[:, 0], kmeans1.cluster_centers_[:, 1], color = 'red', s = 250)
plt.title('Clusters de clientes', fontsize = 20)
plt.xlabel('Ciclo de vida')
plt.ylabel('Cantidad Transaccion')
plt.show()

X3 = dataset.loc[:,['Clientes_edad','Ciclo_de_Vida_sk']].values

wcss = []

for k in range(1,11):
  kmeans2 = KMeans(n_clusters = k, init = 'k-means++')
  kmeans2.fit(X3)
  wcss.append(kmeans2.inertia_)

plt.figure(figsize = (12,7))

plt.plot(range(1, 11), wcss, linewidth = 2, marker = '8')
plt.title('Metodo del codo\n', fontsize = 20)
plt.xlabel('Numero de cluster')
plt.ylabel('Distancia Promedio del centroide al cluster')
plt.show()

kmeans2 = KMeans(n_clusters = 6)
labels = kmeans2.fit_predict(X3)
print(labels)

print(kmeans2.cluster_centers_)

plt.figure(figsize = (14, 8))

plt.scatter(X3[:, 0], X3[:, 1], c = kmeans2.labels_, s = 105)
plt.scatter(kmeans2.cluster_centers_[:, 0], kmeans2.cluster_centers_[:, 1], color = 'red', s = 250)
plt.title('Clusters de clientes', fontsize = 20)
plt.xlabel('Clientes edad')
plt.ylabel('Ciclo de vida')
plt.show()

dataset=dataset.drop(['Genero'], axis=1)

#en este se utliza todos los datos que son numericos si existiese un campo con datos de string este tiene que eliminarse para que el modelo
#pueda trbajar de manera optima pero tambien si no quiere eliminarse se utlizar el metodo one hot encoder pero este es un poco mas tardado
#ya que divide los datos en dos campos y eso ocasiona mas datos y esto puede provocar un cuello de botella 

X4 = dataset.iloc[:,2: ]

wcss= []
for k in range(1, 11):
    kmeans = KMeans(n_clusters = k, init = 'k-means++')
    kmeans.fit(X4)
    wcss.append(kmeans.inertia_)

plt.figure(figsize = (12, 7))

plt.plot(range(1, 11), wcss, linewidth = 2, marker = '8')
plt.title('Metodo del codo\n', fontsize = 20)
plt.xlabel('Numero de cluster')
plt.ylabel('Distancia Promedio del centroide al cluster')
plt.show()

kmeans3 = KMeans(n_clusters = 6)
clusters = kmeans3.fit_predict(X4)
X4['label'] = clusters

fig = px.scatter_3d(X4, x="Clientes_edad", y="Ciclo_de_Vida_sk", z="CantidadTransaccion",
                    color = 'label', size = 'label')
fig.show()

px.scatter(data_frame = dataset, x = 'Clientes_edad', y = 
           'Ciclo_de_Vida_sk',title = 'Relacion entre edad de los clientes con respecto a los ciclos')

fig = px.scatter_3d(X4, x="Clientes_edad", y="Centro_sk", z="CantidadTransaccion",
                    color = 'label', size = 'label')
fig.show()

px.scatter(data_frame = dataset, x = 'Clientes_edad', y = 
           'Centro_sk',title = 'relacion entre edad  y centro')

px.scatter(data_frame = dataset, x = 'Centro_sk', y = 
           'CantidadTransaccion',title = 'relacion entre edad  y transacciones')

fig = px.scatter_3d(X4, x="Clientes_edad", y="CantidadTransaccion", z="MontoAcumuladoventaBs",
                    color = 'label', size = 'label')
fig.show()

fig = px.scatter_3d(X4, x="Clientes_edad", y="Centro_sk", z="Ciclo_de_Vida_sk",
                    color = 'label', size = 'label')
fig.show()

X5 = dataset.iloc[:,0: ]

wcss= []
for k in range(1, 11):
    kmeans = KMeans(n_clusters = k, init = 'k-means++')
    kmeans.fit(X5)
    wcss.append(kmeans.inertia_)

plt.figure(figsize = (12, 7))

plt.plot(range(1, 11), wcss, linewidth = 2, marker = '8')
plt.title('Metodo del codo\n', fontsize = 20)
plt.xlabel('Numero de cluster')
plt.ylabel('Distancia Promedio del centroide al cluster')
plt.show()

kmeans4 = KMeans(n_clusters = 5)
clusters = kmeans4.fit_predict(X5)
X5['label'] = clusters

fig = px.scatter_3d(X5, x="Clientes_sk", y="Clientes_edad", z="Ciclo_de_Vida_sk",
                    color = 'label', size = 'label')
fig.show()

"""### Aglomeracion Jerarquica"""

plt.figure(figsize=(17,8))
dendo = dendrogram(linkage(X3, method = 'ward'))
plt.title('dendrograma', fontsize = 15)
plt.show()

agc = AgglomerativeClustering(n_clusters=5, affinity = 'euclidean', linkage = 'ward')
label = agc.fit_predict(X3)

plt.figure(figsize=(12,8))

plt.scatter(X3[labels == 0,0], X3 [labels == 0,1], label = 'cluster 1', s = 100)
plt.scatter(X3[labels == 1,0], X3 [labels == 1,1], label = 'cluster 2', s = 100)
plt.scatter(X3[labels == 2,0], X3 [labels == 2,1], label = 'cluster 3', s = 100)
plt.scatter(X3[labels == 3,0], X3 [labels == 3,1], label = 'cluster 4', s = 100)
plt.scatter(X3[labels == 4,0], X3 [labels == 4,1], label = 'cluster 5', s = 100)

plt.legend(loc = 'best')
plt.title('cluster de clientes', fontsize = 20)
plt.xlabel('clientes_edad')
plt.ylabel('Ciclo_de_Vida')
plt.show()

plt.figure(figsize=(17,8))
dend = dendrogram(linkage(X1, method = 'ward'))
plt.title('dendrograma', fontsize = 15)
plt.show()

agc = AgglomerativeClustering(n_clusters=5, affinity = 'euclidean', linkage = 'ward')
label = agc.fit_predict(X1)

plt.figure(figsize=(12,8))

plt.scatter(X1[labels == 0,0], X1 [labels == 0,1], label = 'cluster 1', s = 100)
plt.scatter(X1[labels == 1,0], X1 [labels == 1,1], label = 'cluster 2', s = 100)
plt.scatter(X1[labels == 2,0], X1 [labels == 2,1], label = 'cluster 3', s = 100)
plt.scatter(X1[labels == 3,0], X1 [labels == 3,1], label = 'cluster 4', s = 100)
plt.scatter(X1[labels == 4,0], X1 [labels == 4,1], label = 'cluster 5', s = 100)

plt.legend(loc = 'best')
plt.title('cluster de clientes', fontsize = 20)
plt.xlabel('clientes_edad')
plt.ylabel('CantidadTransacciones')
plt.show()

"""### recomendacion fpgrowth"""

! pip install fpgrowth_py

from fpgrowth_py import fpgrowth

dataset_b = pd.read_excel('/content/gdrive/MyDrive/datos/Libro2.xlsx')

dataset_b.head()

#aqui se agrupa el id de los clientes con los productos que compro
grouped_products=dataset_b.groupby('Clientes_id')['Articulo_descripcioncorta'].apply(lambda group_series: group_series.tolist()).reset_index()
groups_lists=grouped_products['Articulo_descripcioncorta'].values.tolist()
#convertir la lista en una tabla
data=list(filter(lambda x: len(x) > 2, groups_lists))

from mlxtend.preprocessing import TransactionEncoder

te = TransactionEncoder()
te_ary = te.fit(data).transform(data)
df= pd.DataFrame(te_ary, columns=te.columns_)
df

from mlxtend.frequent_patterns import fpgrowth

f_patterns = fpgrowth(df, min_support=0.005, use_colnames=True)
f_patterns

import itertools as it
from itertools import *

def partiton(pred, iterable):
  t1, t2 = it.tee(iterable)
  return it.filterfalse(pred, t1), filter(pred, t2)

def part2(el_list):
  pairs = [[[x[1]for x in f]for f in partiton(lambda x: x[0], zip(pattern, el_list))]\
           for pattern in product([True, False], repeat=len(el_list))]
  
  return pairs[1:-1]

supports = f_patterns['support'].to_list()
itemsets = f_patterns['itemsets'].to_list()

patterns_dict = {}
for x in range(len(itemsets)):
  patterns_dict[tuple(sorted(itemsets[x]))] = supports[x]

as_rules_dict = {'left': [], 'right': [], 'confidence': []}
for pattern, support in patterns_dict.items():
  if len(pattern) > 1:
    upper_support = support
    as_rules = part2(pattern)

    for as_r in as_rules:
      left_part = sorted(as_r[0])
      rigth_part = as_r[1]
      lower_support = patterns_dict[tuple(left_part)]
      conf = upper_support / lower_support

      as_rules_dict['left'].append(left_part)
      as_rules_dict['right'].append(rigth_part)
      as_rules_dict['confidence'].append(conf)

strong_as_rules = pd.DataFrame.from_dict(as_rules_dict)
strong_as_rules = strong_as_rules.sort_values('confidence', ascending=False)
strong_as_rules = strong_as_rules[strong_as_rules['confidence']> 0.01]

strong_as_rules

#aqui se crea una canasta (basket) con todos los articulos comprados 

from pandas.core.groupby import groupby
basket = dataset_b.groupby(['Clientes_id','Clientes_sk']).agg({'Articulo_sk' :lambda s:list(set(s))})
basket.head(15)

basket.shape

"""### Recomendacion coseno"""

dataset_a.head(10)

dataset_a.shape

#se contabiliza la cantidad de productos mediante el sk del articulo

dataset_a['Articulo_sk'].value_counts()

dataset_a = dataset_a.loc[dataset_a['CantidadTransaccion']>0]
dataset_a.shape

dataset_a['Clientes_sk'].describe()

dataset_a.columns

#aqui se crea una matriz para ver que que productos compra cada cliente 

custmer_item_maatrix = dataset_a.pivot_table( index='Clientes_sk',
                                           columns='Articulo_sk',
                                           values='CantidadTransaccion',
                                           aggfunc='sum')

custmer_item_maatrix.loc[235:].head()

#este muestra el tamaño de la matriz

custmer_item_maatrix.shape

dataset_a['Clientes_sk'].nunique()

dataset_a['Articulo_sk'].nunique()

custmer_item_maatrix.loc[235:].sum()

#aqui reemplazamos los nan

custmer_item_maatrix = custmer_item_maatrix.applymap(
    lambda x:1 if x>0 else 0)

custmer_item_maatrix.loc[235:].head()

#esta libreria es la que se utilizo 

from sklearn.metrics.pairwise import cosine_similarity

#aqui se usa lo que es el coseno de similitud para crear una matriz

user_sim_matrix=pd.DataFrame(cosine_similarity
                             (custmer_item_maatrix))

user_sim_matrix.head()

#aqui se compara ambas matrices usando la columna y el index
 
user_sim_matrix.columns = custmer_item_maatrix.index

user_sim_matrix['Clientes_sk'] = custmer_item_maatrix.index

user_sim_matrix = user_sim_matrix.set_index('Clientes_sk')

#aqui la matriz ya saca los id de los clientes y los junta con los de la otra matriz 

user_sim_matrix.head()

user_sim_matrix.loc[71655].sort_values(ascending = False)

#aqui ya se saca un cliente y su compra para compararlo con el otro cliente y de esta manera sacar los articulos

items_bought_by_a = set(custmer_item_maatrix.loc[71655]
                        .iloc[custmer_item_maatrix.loc[71655]
                              .to_numpy().nonzero()].index)

items_bought_by_a

items_bought_by_b = set(custmer_item_maatrix.loc[64861]
                        .iloc[custmer_item_maatrix.loc[64861]
                              .to_numpy().nonzero()].index)

items_bought_by_b

items_recomender_by_b = items_bought_by_a - items_bought_by_b

items_recomender_by_b

dataset_a.columns

dataset_a.loc[dataset_a['Articulo_sk'].isin(items_recomender_by_b),
              ['Articulo_sk','Articulo_descripcioncorta','CiclodeVida_descripcion','Centro_sk','Margen 18','stockUnidades','disponibilidad','Articulo_precioventa']].drop_duplicates().set_index('Articulo_sk')

"""### Recomendacion Surprise"""

!pip install scikit-surprise

from surprise import Reader, Dataset, SVD
from surprise.model_selection import train_test_split, cross_validate

reader = Reader()

data = Dataset.load_from_df(dataset_c[['Clientes_id','Articulo_id','Margen18']], reader)

svd = SVD()
cross_validate(svd, data, measures=['RMSE','MAE'],cv=5)

trainset=data.build_full_trainset()
svd.fit(trainset)

dataset_c[dataset_c['Clientes_id']==	3968617	]

"""### Guardar"""

import joblib

dump(X1, 'X1_joblib.pkl')

model_loaded = load('kmeans_joblib.pkl')

encoder_loaded = load('X1_joblib.pkl')

labels = model_loaded.fit_predict(encoder_loaded)
print(labels)

print(model_loaded.cluster_centers_)

type(encoder_loaded)

plt.figure(figsize = (14, 8))

plt.scatter(encoder_loaded[:, 0], encoder_loaded[:, 1], c = model_loaded.labels_, s = 105)
plt.scatter(model_loaded.cluster_centers_[:, 0], model_loaded.cluster_centers_[:, 1], color = 'red', s = 250)
plt.title('Clusters de clientes', fontsize = 20)
plt.xlabel('Clientes edad')
plt.ylabel('Transaccion')
plt.show()